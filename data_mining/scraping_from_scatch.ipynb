{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # For HTML parsing\n",
    "import requests # library for making requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ndtv.com/latest'\n",
    "page=requests.get(url)\n",
    "print(page.status_code) # 200 means the page is downloaded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.text) # This will print the whole HTML content of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(page.text)) # This will print the whole HTML content of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc='''\n",
    "<html>\n",
    "<head>\n",
    "<title>my first website</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>hello world</h1>\n",
    "<p class=\"subtitle\">my first paragraph</p>\n",
    "<p>my second paragraph</p>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "demo_soup=BeautifulSoup(dfc,'lxml')\n",
    "print(demo_soup.find('h1'))\n",
    "print(demo_soup.find_all('p'))\n",
    "print(demo_soup.find('p',class_='subtitle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(demo_soup.find('h1'))\n",
    "item=demo_soup.find('h1')\n",
    "print(item.text)\n",
    "item2=demo_soup.find_all('p')[0] #first paragraph\n",
    "print(item2)\n",
    "print(item2.text)\n",
    "print(item2.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing data from webpage using request object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.text,'lxml')\n",
    "print(soup.find('a'))\n",
    "print(soup.find('h2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt= soup.find_all('h2')  # this will print all the h2 tags\n",
    "nt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nt:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in soup.find_all('span',class_='posted-by'):\n",
    "    print(data.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extracting all news from page to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards= soup.find_all('div',class_='news_Itm')\n",
    "print(len(cards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=[] # empty list\n",
    "for item in cards:\n",
    "    try:title=item.find('h2').text.strip()\n",
    "    except:title=None\n",
    "    try:posted_by=item.find('span',class_='posted-by').text.strip()\n",
    "    except:posted_by=None\n",
    "    try:summary=item.find('p',class_='newsCont').text.strip()\n",
    "    except:summary=None\n",
    "    try: imgurl=item.find('img').attrs.get('src')\n",
    "    except: imgurl=None\n",
    "    #print(title,posted_by,summary)\n",
    "    new_data.append({\n",
    "        'title':title,\n",
    "        'posted_by': posted_by,\n",
    "        'summary': summary,\n",
    "        'imgurl': imgurl\n",
    "    })\n",
    "import pandas as pd\n",
    "pd.DataFrame(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using dputils to extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dputils.scrape import Scraper,Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.ndtv.com/india'\n",
    "scraper=Scraper(url)\n",
    "result=scraper.get_multiple_page_data(\n",
    "    target=Tag(cls='lisingNews'),\n",
    "    items=Tag(cls='news_Itm'),\n",
    "    title=Tag('h2'),\n",
    "    posted_by=Tag('span',cls='posted-by'),\n",
    "    summary=Tag('p',cls='newsCont'),\n",
    "    imgurl=Tag('img',output='src')\n",
    ")\n",
    "df=pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/search?q=mobiles&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "scraper = Scraper(url)\n",
    "out = scraper.get_multiple_page_data(\n",
    "    target=Tag('div', cls='_1YokD2 _3Mn1Gg'),\n",
    "    items=Tag('div', cls='_1AtVbE col-12-12'),\n",
    "    title=Tag('div', cls='_4rR01T'),\n",
    "    price=Tag('div', cls='_30jeq3 _1_WHN1'),\n",
    "    link=Tag('a', cls='_1fQZEK', output='href'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extracting data from a single page with dputils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': '        Adidas Mens Courun Avant M Running Shoe       ',\n",
       " 'price': '2,568.',\n",
       " 'highlights': 'True to size. Order usual size. '}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.amazon.in/Adidas-Synthetic-Courun-Avant-Running/dp/B0C4DPPQHV/ref=sr_1_8?pf_rd_i=1983518031&pf_rd_m=AT95IG9ONZD7S&pf_rd_p=891cd742-586c-42eb-8424-208a4925165b&pf_rd_r=MHX25F7DJRTEHAJQD01S&pf_rd_s=merchandised-search-12&pf_rd_t=101&qid=1700217151&refinements=p_89%3AAdidas&rnid=3837712031&s=shoes&sr=1-8'\n",
    "scraper2 = Scraper(url)\n",
    "scraper2.get_page_data(\n",
    "    product=Tag('span', cls='a-size-large product-title-word-break'),\n",
    "    price=Tag('span',cls='a-price-whole'),\n",
    "    highlights=Tag('span',id='fitRecommendationsLinkRatingText'),\n",
    "    errors=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
